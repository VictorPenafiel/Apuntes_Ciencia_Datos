### Data analisis
Es la cleccion, transformacion y organizacion de los datos para poder hacer predicciones, sacar conclusiones e impulsar la toma de decisiones informadas.

Un dato es la representaci칩n simb칩lica de un hecho. No son exactamente lo mismo, pero en el mundo de la informaci칩n, tratamos al dato como si fuera el hecho mismo.

### Principales habilidades: 
la curiosidad, la comprensi칩n del contexto, la mentalidad t칠cnica, el dise침o de datos y la estrategia de datos.

Ser concientes de las necesidades empresariales

Lo principal es descubrir tendencias, patrones y relaciones

Los cinco porqu칠s es una t칠cnica sencilla pero eficaz para identificar una causa ra칤z. Consiste en preguntar "쯇or qu칠?" repetidamente hasta que se revela la respuesta. Esto suele ocurrir al quinto "por qu칠", pero a veces tendr치 que seguir preguntando m치s veces, otras menos.

los analistas de datos desempe침an un papel fundamental en el 칠xito de sus empresas, pero es importante tener en cuenta que, independientemente de lo valiosa que sea la toma de decisiones basada en los datos, los datos por s칤 solos nunca ser치n tan poderosos como los datos combinados con la experiencia humana, la observaci칩n y, a veces, incluso la intuici칩n.  

### Pensamiento analitico, aspectos claves:
la visualizaci칩n, 
la estrategia, 
la orientaci칩n a los problemas, 
la correlaci칩n
El pensamiento general y orientado a los detalles.

Las fases del proceso de an치lisis de datos son preguntar, preparar, procesar, analizar, compartir y actuar.

### Proceso de an치lisis de datos:

    Pregunte a

    Prepare

    Procesar

    Analizar

    Compartir

    Actuar
    
Los datos pr치cticamente en todas partes. Cada vez que observa y eval칰a algo en el mundo, est치 recopilando y analizando datos. Su an치lisis le ayuda a encontrar formas m치s sencillas de hacer las cosas, a identificar patrones que le ahorran tiempo y a descubrir nuevas perspectivas sorprendentes que pueden cambiar por completo su forma de experimentar las cosas.

쮺칩mo hacen los analistas de datos para dar vida a los datos?
Pues bien, todo empieza con la herramienta de an치lisis de datos adecuada.
Entre ellas se incluyen las hojas de c치lculo, las bases de datos, los lenguajes de consulta y el software de visualizaci칩n

---

### El ciclo de vida de los datos es:

    Planificar: Decidir qu칠 tipo de datos se necesitan, c칩mo se gestionar치n y qui칠n ser치 responsable de ellos.

    Captar: Recopilar o traer datos de distintas fuentes.

    Gestionar: Cuidar y mantener los Datos. Esto incluye determinar c칩mo y d칩nde se almacenan y las herramientas utilizadas para ello.

    Analizar: Utilizar los Datos para resolver problemas, tomar decisiones y respaldar los objetivos empresariales.

    Archivar: Mantener los Datos relevantes almacenados para su consulta a largo plazo y en el futuro.

    Destruir: Sacar los datos del almac칠n y eliminar cualquier copia compartida de los mismos.


### Escuela de Negocios de Harvard (HBS)

Ciclo de vida de los datos basado en la investigaci칩n de la Universidad de Harvard consta de ocho etapas:

    Generaci칩n

    Recopilaci칩n

    Procesamiento

    Almacenamiento 

    Gestionar

    An치lisis

    Visualizaci칩n de datos

    Interpretaci칩n


---

### Ciclo de vida de analisis de datos


    Formular preguntas y definir el problema.

    Preparar los Datos recopilando y almacenando la Informaci칩n.

    Procese los datos limpiando y comprobando la informaci칩n.

    Analice los Datos para encontrar Patrones, Relaciones y Tendencias.

    Comparta los Datos con su p칰blico.

    Act칰e sobre los Datos y utilice los resultados del an치lisis.

---

## <font color='blue'>**1D-CNN aplicado a series de tiempo univariadas.**</font>
<p style='text-align: justify;'>

### **Etapa 1: An치lisis Exploratorio y Limpieza de Datos (EDA) 游늵**

Antes de construir cualquier modelo, es fundamental entender y preparar los datos. En esta primera etapa, realizaremos un **An치lisis Exploratorio de Datos (EDA)** para familiarizarnos con la distribuci칩n, tendencias y caracter칤sticas de la serie temporal de PM2.5. Las librer칤as principales para esta fase son `pandas`, `matplotlib`, `numpy` y `seaborn`.

---

#### **Manejo de Datos Faltantes y Orden Cronol칩gico 游빞**

El primer paso de la preparaci칩n es la limpieza y estructuraci칩n de los datos.

* **Datos Faltantes:** En una serie temporal, los valores ausentes (NAs o `NaN`) pueden romper la continuidad. Existen dos estrategias principales:
    1.  **Eliminaci칩n:** Descartar los registros (filas) que contienen valores faltantes.
    2.  **Imputaci칩n:** 
        1. Usando la media
        2. Usando la mediana
        3. Usando la moda
        4. Calcular una medici칩n apropiada y reemplazar los NAs.
        5. Utilizar modelos estad칤sticos y de Machine Leaning.


* **Orden Cronol칩gico:** A continuaci칩n, se asegura la integridad cronol칩gica de la serie. Dado que en las series de tiempo **el orden es primordial**, se crea una columna `datetime` unificada y se ordena el DataFrame para garantizar que las observaciones est칠n en la secuencia correcta.

---

#### **Visualizaci칩n de la Distribuci칩n y Tendencias**

Una vez que los datos est치n limpios y ordenados, la visualizaci칩n nos ayuda a descubrir patrones.

* **Diagrama de Caja (Box Plot):** Se utiliza para analizar la distribuci칩n de los datos de PM2.5. Este gr치fico es excelente para visualizar r치pidamente el resumen de cinco n칰meros (m칤nimo, cuartiles y m치ximo), identificar la dispersi칩n de los datos y detectar la presencia de **valores at칤picos** (outliers). 

* **Gr치fico de L칤nea:** Complementariamente, un gr치fico de l칤nea muestra la evoluci칩n de la variable PM2.5 a lo largo del tiempo, permitiendo identificar patrones generales, **tendencias y estacionalidad**.

---

### **Etapa 2: Preprocesamiento y Transformaci칩n de Datos 丘뙖잺**

<p style='text-align: justify;'>
En esta segunda etapa preparamos los datos con el objetivo de realizar un entrenamiento robusto de nuestra red neuronal. Usualmente los datos como primera etapa se normalizan. Empiricamente se ha observando que los datos normalizados (No siempre) generan modelos de clasificiaci칩n y de regresi칩n con mejores metricas que los no normalizadas. Por otra parte, Los algoritmos de descenso de gradiente funcionan mejor (por ejemplo, convergen m치s r치pido) si las variables est치n dentro del rango [-1, 1]. Muchas fuentes relajan el l칤mite incluso [-3, 3].</p>
<p style='text-align: justify;'>
Posteriormente los datos debens ser separados en tres conjuntos: Entrenamiento, validaci칩n y test. Usualmente el ultimo de test se utiliza con una prueba nueva de datos. Finalmente debemos construir el conjunto de vectores que ser치n utilizados para entrenar la red neuronal perceptron multicapa. Las librerias. Adicionalmente en esta secci칩n utilizaremos la librer칤a sklearn para realizar la normalizaci칩n.
</p>

---

#### **Normalizaci칩n de Datos**

El primer paso es la **normalizaci칩n**. Se escalan los valores de `pm2.5` a un rango entre 0 y 1. Esta t칠cnica es casi obligatoria en redes neuronales, ya que ayuda a que los algoritmos de optimizaci칩n (como el descenso de gradiente) converjan m치s r치pido y de forma m치s estable. Un modelo entrenado con datos normalizados generalmente produce mejores resultados.

---

#### **Divisi칩n del Conjunto de Datos: Entrenamiento y Validaci칩n**

El modelo necesita datos para aprender y datos para ser evaluado. Por ello, el conjunto de datos se divide cronol칩gicamente en:

* **Conjunto de Entrenamiento (Training Set):** Se utiliza para entrenar el modelo. Aqu칤, la red ajusta sus pesos mediante el c치lculo de la funci칩n de p칠rdida y la retropropagaci칩n (*backpropagation*).
* **Conjunto de Validaci칩n (Validation Set):** Se usa para evaluar el rendimiento del modelo en datos que no ha visto durante el entrenamiento. Es crucial para detectar el **sobreajuste** (*overfitting*) y para ajustar hiperpar치metros como el n칰mero de 칠pocas.

---

#### **Transformaci칩n para Aprendizaje Supervisado*

Una serie temporal, por s칤 misma, no tiene un formato de entrada (`X`) y salida (`y`). Para que la red neuronal pueda aprender, debemos transformarla en un problema de **aprendizaje supervisado**. 

En este caso, se define que para predecir el valor de PM2.5 en una hora determinada (`y`), el modelo utilizar치 como informaci칩n las mediciones de las **7 horas anteriores** (`X`). Se crea una funci칩n que recorre la serie y genera estos pares `(X, y)`, preparando as칤 los vectores de entrada para el entrenamiento del modelo. La elecci칩n de una ventana de 7 horas se basa en la observaci칩n de patrones en los datos.